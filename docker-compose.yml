services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_models:/root/.ollama
    networks:
      - appnet
    deploy:
      resources:
        limits:
          memory: 8G  # <-- increase as needed
        reservations:
          memory: 4G
          #devices:
          #  - driver: nvidia
          #    count: all
          #    capabilities: [gpu]

  humaneval:
    build: 
      context: . 
    container_name: humaneval_sandbox
    stdin_open: true
    tty: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    pids_limit: 64
    mem_limit: 256m
    cpus: 1.0
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - ./ollama_models:/root/.ollama    # same shared folder as ollama
    networks:
      - appnet             # same network as ollama
    depends_on:
      - ollama

volumes:
  ollama_data:

networks:
  appnet:
    driver: bridge